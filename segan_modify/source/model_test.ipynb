{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed arguments:  {'deconv_type': 'deconv', 'd_label_smooth': 0.25, 'z_depth': 256, 'preemph': 0.95, 'seed': 111, 'init_noise_std': 0.0, 'synthesis_path': 'dwavegan_samples', 'e2e_dataset': 'data/segan.tfrecords', 'save_freq': 50, 'g_type': 'ae', 'l1_remove_epoch': 150, 'epoch': 120, 'bias_D_conv': True, 'save_path': 'train_record_weights', 'test_wav': None, 'g_learning_rate': 0.0002, 'unrolled_lstm': False, 'z_dim': 256, 'batch_size': 100, 'bias_downconv': True, 'denoise_epoch': 5, 'canvas_size': 16384, 'noise_decay': 0.7, 'g_nl': 'prelu', 'beta_1': 0.5, 'd_learning_rate': 0.0002, 'denoise_lbound': 0.01, 'bias_deconv': True, 'weights': 'SEGAN-41700', 'model': 'gan', 'save_clean_path': 'test_clean_results', 'init_l1_weight': 100.0}\n",
      "Using device:  /cpu:0\n",
      "Creating GAN model\n",
      "*** Applying pre-emphasis of 0.95 ***\n",
      "!!!!!!!!initaial wieght\n",
      "*** Building Generator ***\n",
      "Biasing downconv in G\n",
      "Downconv (100, 16384, 1) -> (100, 8192, 16)\n",
      "Adding skip connection downconv 0\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 8192, 16) -> (100, 4096, 32)\n",
      "Adding skip connection downconv 1\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 4096, 32) -> (100, 2048, 32)\n",
      "Adding skip connection downconv 2\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 2048, 32) -> (100, 1024, 64)\n",
      "Adding skip connection downconv 3\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 1024, 64) -> (100, 512, 64)\n",
      "Adding skip connection downconv 4\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 512, 64) -> (100, 256, 128)\n",
      "Adding skip connection downconv 5\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 256, 128) -> (100, 128, 128)\n",
      "Adding skip connection downconv 6\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 128, 128) -> (100, 64, 256)\n",
      "Adding skip connection downconv 7\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 64, 256) -> (100, 32, 256)\n",
      "Adding skip connection downconv 8\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 32, 256) -> (100, 16, 512)\n",
      "Adding skip connection downconv 9\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 16, 512) -> (100, 8, 1024)\n",
      "-- Enc: prelu activation --\n",
      "g_dec_depths:  [512, 256, 256, 128, 128, 64, 64, 32, 32, 16, 1]\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 8, 2048) -> (100, 16, 512)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 16, 512)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 16, 1024) -> (100, 32, 256)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 32, 256)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 32, 512) -> (100, 64, 256)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 64, 256)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 64, 512) -> (100, 128, 128)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 128, 128)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 128, 256) -> (100, 256, 128)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 256, 128)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 256, 256) -> (100, 512, 64)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 512, 64)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 512, 128) -> (100, 1024, 64)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 1024, 64)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 1024, 128) -> (100, 2048, 32)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 2048, 32)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 2048, 64) -> (100, 4096, 32)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 4096, 32)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 4096, 64) -> (100, 8192, 16)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 8192, 16)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 8192, 32) -> (100, 16384, 1)\n",
      "-- Dec: tanh activation --\n",
      "Amount of alpha vectors:  21\n",
      "Amount of skip connections:  10\n",
      "Last wave shape:  (100, 16384, 1)\n",
      "*************************\n",
      "num of G returned:  23\n",
      "*** Discriminator summary ***\n",
      "D block 0 input shape: (100, 16384, 2) *** biasing D conv *** downconved shape: (100, 8192, 16)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 1 input shape: (100, 8192, 16) *** biasing D conv *** downconved shape: (100, 4096, 32)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 2 input shape: (100, 4096, 32) *** biasing D conv *** downconved shape: (100, 2048, 32)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 3 input shape: (100, 2048, 32) *** biasing D conv *** downconved shape: (100, 1024, 64)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 4 input shape: (100, 1024, 64) *** biasing D conv *** downconved shape: (100, 512, 64)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 5 input shape: (100, 512, 64) *** biasing D conv *** downconved shape: (100, 256, 128)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 6 input shape: (100, 256, 128) *** biasing D conv *** downconved shape: (100, 128, 128)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 7 input shape: (100, 128, 128) *** biasing D conv *** downconved shape: (100, 64, 256)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 8 input shape: (100, 64, 256) *** biasing D conv *** downconved shape: (100, 32, 256)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 9 input shape: (100, 32, 256) *** biasing D conv *** downconved shape: (100, 16, 512)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 10 input shape: (100, 16, 512) *** biasing D conv *** downconved shape: (100, 8, 1024)  *** Applying VBN *** Applying Lrelu *** \n",
      "discriminator deconved shape:  (100, 8, 1024)\n",
      "discriminator output shape:  (100, 1)\n",
      "*****************************\n",
      "Not clipping D weights\n",
      "Initializing optimizers...\n",
      "Initializing variables...\n",
      "Sampling some wavs to store sample references...\n",
      "sample noisy shape:  (100, 16384)\n",
      "sample wav shape:  (100, 16384)\n",
      "sample z shape:  (100, 8, 1024)\n",
      "total examples in TFRecords data/segan.tfrecords: 306\n",
      "Batches per epoch:  3\n",
      "[*] Reading checkpoints...\n",
      "train_record_weights\n",
      "[*] Read SEGAN-41700\n",
      "[*] Load SUCCESS\n",
      "0/360 (epoch 0), d_rl_loss = 0.02228, d_fk_loss = 0.59118, g_adv_loss = 1.05398, g_l1_loss = 0.57322, time/batch = 91.15236, mtime/batch = 91.15236\n",
      "1/360 (epoch 0), d_rl_loss = 0.09667, d_fk_loss = 0.00168, g_adv_loss = 0.95256, g_l1_loss = 0.49407, time/batch = 89.31564, mtime/batch = 90.23400\n",
      "2/360 (epoch 0), d_rl_loss = 0.04872, d_fk_loss = 0.00070, g_adv_loss = 0.97260, g_l1_loss = 0.41770, time/batch = 88.73886, mtime/batch = 89.73562\n",
      "3/360 (epoch 1), d_rl_loss = 0.04003, d_fk_loss = 0.00012, g_adv_loss = 0.97840, g_l1_loss = 0.43873, time/batch = 89.46227, mtime/batch = 89.66728\n",
      "4/360 (epoch 1), d_rl_loss = 0.00750, d_fk_loss = 0.00010, g_adv_loss = 0.99753, g_l1_loss = 0.39818, time/batch = 90.16465, mtime/batch = 89.76676\n",
      "5/360 (epoch 1), d_rl_loss = 0.00106, d_fk_loss = 0.00008, g_adv_loss = 0.99517, g_l1_loss = 0.40617, time/batch = 89.63738, mtime/batch = 89.74519\n",
      "6/360 (epoch 2), d_rl_loss = 0.00197, d_fk_loss = 0.11919, g_adv_loss = 1.00872, g_l1_loss = 0.42099, time/batch = 89.82784, mtime/batch = 89.75700\n",
      "7/360 (epoch 2), d_rl_loss = 0.01241, d_fk_loss = 0.00003, g_adv_loss = 1.00496, g_l1_loss = 0.37048, time/batch = 88.67242, mtime/batch = 89.62143\n",
      "8/360 (epoch 2), d_rl_loss = 0.00823, d_fk_loss = 0.00010, g_adv_loss = 0.99523, g_l1_loss = 0.40912, time/batch = 90.72888, mtime/batch = 89.74448\n",
      "9/360 (epoch 3), d_rl_loss = 0.00385, d_fk_loss = 0.00008, g_adv_loss = 0.98722, g_l1_loss = 0.37990, time/batch = 89.58666, mtime/batch = 89.72870\n",
      "10/360 (epoch 3), d_rl_loss = 0.00146, d_fk_loss = 0.00023, g_adv_loss = 0.98587, g_l1_loss = 0.37249, time/batch = 90.25506, mtime/batch = 89.77655\n",
      "11/360 (epoch 3), d_rl_loss = 0.00136, d_fk_loss = 0.00058, g_adv_loss = 1.00912, g_l1_loss = 0.41485, time/batch = 89.38257, mtime/batch = 89.74372\n",
      "12/360 (epoch 4), d_rl_loss = 0.00120, d_fk_loss = 0.00040, g_adv_loss = 0.96714, g_l1_loss = 0.38574, time/batch = 90.20084, mtime/batch = 89.77888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/360 (epoch 4), d_rl_loss = 0.00095, d_fk_loss = 0.00050, g_adv_loss = 0.99824, g_l1_loss = 0.38389, time/batch = 90.44297, mtime/batch = 89.82632\n",
      "14/360 (epoch 4), d_rl_loss = 0.00178, d_fk_loss = 0.00012, g_adv_loss = 0.99486, g_l1_loss = 0.35485, time/batch = 90.86960, mtime/batch = 89.89587\n",
      "New noise std 0.0 < lbound 0.01, setting 0.\n",
      "** De-activating noise layer **\n",
      "15/360 (epoch 5), d_rl_loss = 0.00080, d_fk_loss = 0.00020, g_adv_loss = 0.98758, g_l1_loss = 0.39877, time/batch = 90.05752, mtime/batch = 89.90597\n",
      "16/360 (epoch 5), d_rl_loss = 0.00052, d_fk_loss = 0.04783, g_adv_loss = 1.02672, g_l1_loss = 0.36873, time/batch = 90.78576, mtime/batch = 89.95772\n",
      "17/360 (epoch 5), d_rl_loss = 0.04931, d_fk_loss = 0.00002, g_adv_loss = 0.96663, g_l1_loss = 0.35786, time/batch = 90.66022, mtime/batch = 89.99675\n",
      "18/360 (epoch 6), d_rl_loss = 0.02740, d_fk_loss = 0.00018, g_adv_loss = 1.00408, g_l1_loss = 0.35600, time/batch = 92.28677, mtime/batch = 90.11728\n",
      "19/360 (epoch 6), d_rl_loss = 0.00346, d_fk_loss = 0.02675, g_adv_loss = 1.00557, g_l1_loss = 0.31357, time/batch = 92.74699, mtime/batch = 90.24876\n",
      "20/360 (epoch 6), d_rl_loss = 0.00230, d_fk_loss = 0.00041, g_adv_loss = 0.95943, g_l1_loss = 0.40418, time/batch = 91.64300, mtime/batch = 90.31516\n",
      "21/360 (epoch 7), d_rl_loss = 0.00194, d_fk_loss = 0.00045, g_adv_loss = 1.02756, g_l1_loss = 0.40239, time/batch = 90.82213, mtime/batch = 90.33820\n",
      "22/360 (epoch 7), d_rl_loss = 0.00166, d_fk_loss = 0.00044, g_adv_loss = 0.96789, g_l1_loss = 0.45003, time/batch = 90.91410, mtime/batch = 90.36324\n",
      "23/360 (epoch 7), d_rl_loss = 0.00058, d_fk_loss = 0.00069, g_adv_loss = 1.06826, g_l1_loss = 0.44022, time/batch = 90.33419, mtime/batch = 90.36203\n",
      "24/360 (epoch 8), d_rl_loss = 0.00059, d_fk_loss = 0.00067, g_adv_loss = 0.97182, g_l1_loss = 0.39246, time/batch = 91.18361, mtime/batch = 90.39489\n",
      "25/360 (epoch 8), d_rl_loss = 0.00036, d_fk_loss = 0.00041, g_adv_loss = 1.01989, g_l1_loss = 0.37876, time/batch = 90.48023, mtime/batch = 90.39817\n",
      "26/360 (epoch 8), d_rl_loss = 0.00054, d_fk_loss = 0.00012, g_adv_loss = 0.99269, g_l1_loss = 0.42119, time/batch = 91.18571, mtime/batch = 90.42734\n",
      "27/360 (epoch 9), d_rl_loss = 0.00036, d_fk_loss = 0.00002, g_adv_loss = 0.98688, g_l1_loss = 0.33017, time/batch = 90.58541, mtime/batch = 90.43299\n",
      "28/360 (epoch 9), d_rl_loss = 0.00081, d_fk_loss = 0.00002, g_adv_loss = 1.00306, g_l1_loss = 0.37959, time/batch = 90.63360, mtime/batch = 90.43991\n",
      "29/360 (epoch 9), d_rl_loss = 0.00069, d_fk_loss = 0.16741, g_adv_loss = 0.99866, g_l1_loss = 0.37312, time/batch = 90.52510, mtime/batch = 90.44275\n",
      "30/360 (epoch 10), d_rl_loss = 0.07920, d_fk_loss = 0.00017, g_adv_loss = 0.99112, g_l1_loss = 0.41132, time/batch = 90.75395, mtime/batch = 90.45278\n",
      "31/360 (epoch 10), d_rl_loss = 0.00886, d_fk_loss = 0.00001, g_adv_loss = 1.02087, g_l1_loss = 0.39516, time/batch = 90.36735, mtime/batch = 90.45011\n",
      "32/360 (epoch 10), d_rl_loss = 0.00211, d_fk_loss = 0.00005, g_adv_loss = 0.99937, g_l1_loss = 0.30430, time/batch = 90.99711, mtime/batch = 90.46669\n",
      "33/360 (epoch 11), d_rl_loss = 0.00118, d_fk_loss = 0.00003, g_adv_loss = 1.00623, g_l1_loss = 0.31254, time/batch = 90.41698, mtime/batch = 90.46523\n",
      "34/360 (epoch 11), d_rl_loss = 0.00093, d_fk_loss = 0.00003, g_adv_loss = 1.00004, g_l1_loss = 0.35453, time/batch = 90.93399, mtime/batch = 90.47862\n",
      "35/360 (epoch 11), d_rl_loss = 0.00143, d_fk_loss = 0.00009, g_adv_loss = 0.98647, g_l1_loss = 0.30059, time/batch = 90.65991, mtime/batch = 90.48366\n",
      "36/360 (epoch 12), d_rl_loss = 0.00045, d_fk_loss = 0.00029, g_adv_loss = 0.99244, g_l1_loss = 0.33640, time/batch = 91.72930, mtime/batch = 90.51732\n",
      "37/360 (epoch 12), d_rl_loss = 0.00079, d_fk_loss = 0.00057, g_adv_loss = 0.97807, g_l1_loss = 0.34911, time/batch = 90.72803, mtime/batch = 90.52287\n",
      "38/360 (epoch 12), d_rl_loss = 0.00029, d_fk_loss = 0.05046, g_adv_loss = 0.98458, g_l1_loss = 0.38025, time/batch = 90.33044, mtime/batch = 90.51793\n",
      "39/360 (epoch 13), d_rl_loss = 0.01166, d_fk_loss = 0.00036, g_adv_loss = 1.01317, g_l1_loss = 0.32997, time/batch = 88.98703, mtime/batch = 90.47966\n",
      "40/360 (epoch 13), d_rl_loss = 0.00272, d_fk_loss = 0.00029, g_adv_loss = 0.99781, g_l1_loss = 0.29875, time/batch = 91.27567, mtime/batch = 90.49908\n",
      "41/360 (epoch 13), d_rl_loss = 0.00567, d_fk_loss = 0.00019, g_adv_loss = 0.99619, g_l1_loss = 0.31158, time/batch = 90.82015, mtime/batch = 90.50672\n",
      "42/360 (epoch 14), d_rl_loss = 0.00193, d_fk_loss = 0.01780, g_adv_loss = 1.02895, g_l1_loss = 0.32175, time/batch = 90.82491, mtime/batch = 90.51412\n",
      "43/360 (epoch 14), d_rl_loss = 0.00435, d_fk_loss = 0.00043, g_adv_loss = 0.97026, g_l1_loss = 0.32028, time/batch = 90.52225, mtime/batch = 90.51431\n",
      "44/360 (epoch 14), d_rl_loss = 0.00085, d_fk_loss = 0.00020, g_adv_loss = 1.01632, g_l1_loss = 0.33331, time/batch = 90.48830, mtime/batch = 90.51373\n",
      "45/360 (epoch 15), d_rl_loss = 0.00103, d_fk_loss = 0.00022, g_adv_loss = 0.97114, g_l1_loss = 0.32004, time/batch = 90.70161, mtime/batch = 90.51781\n",
      "46/360 (epoch 15), d_rl_loss = 0.00042, d_fk_loss = 0.00023, g_adv_loss = 1.02484, g_l1_loss = 0.33280, time/batch = 90.41367, mtime/batch = 90.51560\n",
      "47/360 (epoch 15), d_rl_loss = 0.00040, d_fk_loss = 0.00002, g_adv_loss = 0.99768, g_l1_loss = 0.33200, time/batch = 88.90212, mtime/batch = 90.48198\n",
      "48/360 (epoch 16), d_rl_loss = 0.00053, d_fk_loss = 0.00022, g_adv_loss = 0.99507, g_l1_loss = 0.36571, time/batch = 91.04622, mtime/batch = 90.49350\n",
      "49/360 (epoch 16), d_rl_loss = 0.00122, d_fk_loss = 0.00007, g_adv_loss = 1.00456, g_l1_loss = 0.36157, time/batch = 90.60244, mtime/batch = 90.49568\n",
      "w0 max: 0.0218768101186 min: -0.0263552740216\n",
      "w1 max: 0.0275569316 min: -0.0298092085868\n",
      "w2 max: 0.0351125374436 min: -0.0359091721475\n",
      "w3 max: 0.0495541878045 min: -0.0434663370252\n",
      "w4 max: 0.051801327616 min: -0.0632482245564\n",
      "w5 max: 0.0707972869277 min: -0.0608097165823\n",
      "w6 max: 0.0303968284279 min: -0.0325077362359\n",
      "w7 max: 0.108209848404 min: -0.079431116581\n",
      "w8 max: 0.0485680103302 min: -0.0472201630473\n",
      "w9 max: 0.114163443446 min: -0.122547999024\n",
      "w10 max: 0.09879861027 min: -0.103139184415\n",
      "w11 max: 0.127742230892 min: -0.102497205138\n",
      "w12 max: 0.0701719969511 min: -0.087511844933\n",
      "w13 max: 0.106984779239 min: -0.112710773945\n",
      "w14 max: 0.0948910191655 min: -0.0725010484457\n",
      "w15 max: 0.0208022966981 min: -0.0195649191737\n",
      "w16 max: 0.0312385559082 min: -0.0387527421117\n",
      "w17 max: 0.0188086777925 min: -0.0232127569616\n",
      "w18 max: 0.0554620660841 min: -0.0512997470796\n",
      "w19 max: 0.079159848392 min: -0.065309278667\n",
      "50/360 (epoch 16), d_rl_loss = 0.00047, d_fk_loss = 0.00006, g_adv_loss = 1.00442, g_l1_loss = 0.27886, time/batch = 89.50824, mtime/batch = 90.47631\n",
      "51/360 (epoch 17), d_rl_loss = 0.00038, d_fk_loss = 0.00013, g_adv_loss = 1.00552, g_l1_loss = 0.30030, time/batch = 90.90870, mtime/batch = 90.48463\n",
      "52/360 (epoch 17), d_rl_loss = 0.00029, d_fk_loss = 0.00009, g_adv_loss = 0.99135, g_l1_loss = 0.33484, time/batch = 89.48700, mtime/batch = 90.46581\n",
      "53/360 (epoch 17), d_rl_loss = 0.00025, d_fk_loss = 0.00005, g_adv_loss = 1.01264, g_l1_loss = 0.31303, time/batch = 90.61070, mtime/batch = 90.46849\n",
      "54/360 (epoch 18), d_rl_loss = 0.00031, d_fk_loss = 0.00001, g_adv_loss = 1.00447, g_l1_loss = 0.32024, time/batch = 89.54470, mtime/batch = 90.45169\n",
      "55/360 (epoch 18), d_rl_loss = 0.00079, d_fk_loss = 0.00077, g_adv_loss = 1.01259, g_l1_loss = 0.35187, time/batch = 90.88287, mtime/batch = 90.45939\n",
      "56/360 (epoch 18), d_rl_loss = 0.00074, d_fk_loss = 0.00013, g_adv_loss = 0.99912, g_l1_loss = 0.32644, time/batch = 90.25062, mtime/batch = 90.45573\n",
      "57/360 (epoch 19), d_rl_loss = 0.00032, d_fk_loss = 0.00007, g_adv_loss = 0.99490, g_l1_loss = 0.34418, time/batch = 90.05000, mtime/batch = 90.44873\n",
      "58/360 (epoch 19), d_rl_loss = 0.00023, d_fk_loss = 0.00010, g_adv_loss = 1.01797, g_l1_loss = 0.29416, time/batch = 90.18099, mtime/batch = 90.44420\n",
      "59/360 (epoch 19), d_rl_loss = 0.00025, d_fk_loss = 0.00007, g_adv_loss = 0.98324, g_l1_loss = 0.36528, time/batch = 90.60915, mtime/batch = 90.44695\n",
      "60/360 (epoch 20), d_rl_loss = 0.00021, d_fk_loss = 0.00009, g_adv_loss = 1.01205, g_l1_loss = 0.27766, time/batch = 90.16872, mtime/batch = 90.44238\n",
      "61/360 (epoch 20), d_rl_loss = 0.00018, d_fk_loss = 0.00004, g_adv_loss = 0.99838, g_l1_loss = 0.28934, time/batch = 90.73438, mtime/batch = 90.44709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/360 (epoch 20), d_rl_loss = 0.00026, d_fk_loss = 0.02802, g_adv_loss = 1.00598, g_l1_loss = 0.29387, time/batch = 90.05958, mtime/batch = 90.44094\n",
      "63/360 (epoch 21), d_rl_loss = 0.03560, d_fk_loss = 0.00011, g_adv_loss = 0.97623, g_l1_loss = 0.31123, time/batch = 90.70800, mtime/batch = 90.44512\n",
      "64/360 (epoch 21), d_rl_loss = 0.00742, d_fk_loss = 0.00020, g_adv_loss = 1.01227, g_l1_loss = 0.30861, time/batch = 90.09917, mtime/batch = 90.43979\n",
      "65/360 (epoch 21), d_rl_loss = 0.00162, d_fk_loss = 0.07896, g_adv_loss = 1.07836, g_l1_loss = 0.29325, time/batch = 90.81182, mtime/batch = 90.44543\n",
      "66/360 (epoch 22), d_rl_loss = 0.01712, d_fk_loss = 0.00020, g_adv_loss = 1.00918, g_l1_loss = 0.33681, time/batch = 90.34442, mtime/batch = 90.44392\n",
      "67/360 (epoch 22), d_rl_loss = 0.00371, d_fk_loss = 0.00022, g_adv_loss = 0.95733, g_l1_loss = 0.31793, time/batch = 90.34806, mtime/batch = 90.44251\n",
      "68/360 (epoch 22), d_rl_loss = 0.00238, d_fk_loss = 0.00068, g_adv_loss = 1.06248, g_l1_loss = 0.29236, time/batch = 88.81025, mtime/batch = 90.41886\n",
      "69/360 (epoch 23), d_rl_loss = 0.00203, d_fk_loss = 0.00194, g_adv_loss = 0.96173, g_l1_loss = 0.34512, time/batch = 90.77365, mtime/batch = 90.42393\n",
      "70/360 (epoch 23), d_rl_loss = 0.00374, d_fk_loss = 0.00070, g_adv_loss = 1.05753, g_l1_loss = 0.29426, time/batch = 89.35000, mtime/batch = 90.40880\n",
      "71/360 (epoch 23), d_rl_loss = 0.00157, d_fk_loss = 0.00030, g_adv_loss = 1.01220, g_l1_loss = 0.30388, time/batch = 90.52037, mtime/batch = 90.41035\n",
      "72/360 (epoch 24), d_rl_loss = 0.00066, d_fk_loss = 0.00012, g_adv_loss = 1.02893, g_l1_loss = 0.28234, time/batch = 89.47849, mtime/batch = 90.39758\n",
      "73/360 (epoch 24), d_rl_loss = 0.00063, d_fk_loss = 0.00060, g_adv_loss = 0.98255, g_l1_loss = 0.28663, time/batch = 90.08543, mtime/batch = 90.39337\n",
      "74/360 (epoch 24), d_rl_loss = 0.00040, d_fk_loss = 0.00001, g_adv_loss = 1.00697, g_l1_loss = 0.30677, time/batch = 90.26544, mtime/batch = 90.39166\n",
      "75/360 (epoch 25), d_rl_loss = 0.00043, d_fk_loss = 0.00002, g_adv_loss = 0.99222, g_l1_loss = 0.29283, time/batch = 90.11184, mtime/batch = 90.38798\n",
      "76/360 (epoch 25), d_rl_loss = 0.00038, d_fk_loss = 0.00007, g_adv_loss = 1.03266, g_l1_loss = 0.27108, time/batch = 90.20536, mtime/batch = 90.38561\n",
      "77/360 (epoch 25), d_rl_loss = 0.00023, d_fk_loss = 0.00008, g_adv_loss = 1.00204, g_l1_loss = 0.32039, time/batch = 90.69238, mtime/batch = 90.38954\n",
      "78/360 (epoch 26), d_rl_loss = 0.00016, d_fk_loss = 0.00006, g_adv_loss = 0.98609, g_l1_loss = 0.31675, time/batch = 90.15491, mtime/batch = 90.38657\n",
      "79/360 (epoch 26), d_rl_loss = 0.00023, d_fk_loss = 0.00013, g_adv_loss = 1.01219, g_l1_loss = 0.27364, time/batch = 90.68162, mtime/batch = 90.39026\n",
      "80/360 (epoch 26), d_rl_loss = 0.00040, d_fk_loss = 0.00007, g_adv_loss = 1.00789, g_l1_loss = 0.29581, time/batch = 89.94852, mtime/batch = 90.38480\n",
      "81/360 (epoch 27), d_rl_loss = 0.00045, d_fk_loss = 0.00780, g_adv_loss = 1.00404, g_l1_loss = 0.27988, time/batch = 90.49118, mtime/batch = 90.38610\n",
      "82/360 (epoch 27), d_rl_loss = 0.00203, d_fk_loss = 0.00014, g_adv_loss = 1.00861, g_l1_loss = 0.31672, time/batch = 90.04996, mtime/batch = 90.38205\n",
      "83/360 (epoch 27), d_rl_loss = 0.00059, d_fk_loss = 0.00003, g_adv_loss = 0.99098, g_l1_loss = 0.31074, time/batch = 90.66899, mtime/batch = 90.38547\n",
      "84/360 (epoch 28), d_rl_loss = 0.00088, d_fk_loss = 0.00009, g_adv_loss = 1.03528, g_l1_loss = 0.27286, time/batch = 90.32317, mtime/batch = 90.38473\n",
      "85/360 (epoch 28), d_rl_loss = 0.00149, d_fk_loss = 0.00016, g_adv_loss = 0.98952, g_l1_loss = 0.25106, time/batch = 90.75190, mtime/batch = 90.38900\n",
      "86/360 (epoch 28), d_rl_loss = 0.00274, d_fk_loss = 0.00004, g_adv_loss = 1.00064, g_l1_loss = 0.26972, time/batch = 90.21606, mtime/batch = 90.38702\n",
      "87/360 (epoch 29), d_rl_loss = 0.00334, d_fk_loss = 0.00073, g_adv_loss = 0.96152, g_l1_loss = 0.27005, time/batch = 90.74184, mtime/batch = 90.39105\n",
      "88/360 (epoch 29), d_rl_loss = 0.00129, d_fk_loss = 0.00056, g_adv_loss = 1.02286, g_l1_loss = 0.29176, time/batch = 90.28597, mtime/batch = 90.38987\n",
      "89/360 (epoch 29), d_rl_loss = 0.00058, d_fk_loss = 0.00021, g_adv_loss = 1.01769, g_l1_loss = 0.29814, time/batch = 90.75712, mtime/batch = 90.39395\n",
      "90/360 (epoch 30), d_rl_loss = 0.00048, d_fk_loss = 0.00008, g_adv_loss = 0.99322, g_l1_loss = 0.27822, time/batch = 90.37324, mtime/batch = 90.39372\n",
      "91/360 (epoch 30), d_rl_loss = 0.00055, d_fk_loss = 0.00015, g_adv_loss = 1.01717, g_l1_loss = 0.26833, time/batch = 90.74183, mtime/batch = 90.39750\n",
      "92/360 (epoch 30), d_rl_loss = 0.00040, d_fk_loss = 0.00010, g_adv_loss = 0.98287, g_l1_loss = 0.31497, time/batch = 90.21425, mtime/batch = 90.39553\n",
      "93/360 (epoch 31), d_rl_loss = 0.00019, d_fk_loss = 0.00006, g_adv_loss = 0.99819, g_l1_loss = 0.29845, time/batch = 90.56101, mtime/batch = 90.39729\n",
      "94/360 (epoch 31), d_rl_loss = 0.00013, d_fk_loss = 0.00001, g_adv_loss = 0.99325, g_l1_loss = 0.25542, time/batch = 89.44102, mtime/batch = 90.38723\n",
      "95/360 (epoch 31), d_rl_loss = 0.00016, d_fk_loss = 0.00006, g_adv_loss = 0.99513, g_l1_loss = 0.31668, time/batch = 91.06268, mtime/batch = 90.39426\n",
      "96/360 (epoch 32), d_rl_loss = 0.00020, d_fk_loss = 0.00002, g_adv_loss = 0.99480, g_l1_loss = 0.30108, time/batch = 90.25516, mtime/batch = 90.39283\n",
      "97/360 (epoch 32), d_rl_loss = 0.00057, d_fk_loss = 0.00005, g_adv_loss = 1.00750, g_l1_loss = 0.29045, time/batch = 90.69983, mtime/batch = 90.39596\n",
      "98/360 (epoch 32), d_rl_loss = 0.00100, d_fk_loss = 0.00001, g_adv_loss = 1.00849, g_l1_loss = 0.25798, time/batch = 90.39340, mtime/batch = 90.39594\n",
      "99/360 (epoch 33), d_rl_loss = 0.00131, d_fk_loss = 0.00004, g_adv_loss = 0.99036, g_l1_loss = 0.28208, time/batch = 90.76042, mtime/batch = 90.39958\n",
      "w0 max: 0.010678791441 min: -0.0111057544127\n",
      "w1 max: 0.0200107004493 min: -0.0194309446961\n",
      "w2 max: 0.0239744260907 min: -0.0261829663068\n",
      "w3 max: 0.0413970053196 min: -0.0365150459111\n",
      "w4 max: 0.043935701251 min: -0.0544056147337\n",
      "w5 max: 0.0555417239666 min: -0.0487395115197\n",
      "w6 max: 0.0236710552126 min: -0.0265477634966\n",
      "w7 max: 0.121555328369 min: -0.0873537883162\n",
      "w8 max: 0.0435827597976 min: -0.038242880255\n",
      "w9 max: 0.093282610178 min: -0.103803351521\n",
      "w10 max: 0.0835894495249 min: -0.090596280992\n",
      "w11 max: 0.11348619312 min: -0.0920085459948\n",
      "w12 max: 0.0628415197134 min: -0.0730506703258\n",
      "w13 max: 0.0911182835698 min: -0.0994340255857\n",
      "w14 max: 0.108220666647 min: -0.0800254270434\n",
      "w15 max: 0.0160159636289 min: -0.0165592934936\n",
      "w16 max: 0.024019151926 min: -0.0284609068185\n",
      "w17 max: 0.0133135318756 min: -0.0146457748488\n",
      "w18 max: 0.0453166030347 min: -0.0398789867759\n",
      "w19 max: 0.0872004926205 min: -0.0753282755613\n",
      "100/360 (epoch 33), d_rl_loss = 0.00130, d_fk_loss = 0.00015, g_adv_loss = 1.03293, g_l1_loss = 0.28991, time/batch = 90.58391, mtime/batch = 90.40141\n",
      "101/360 (epoch 33), d_rl_loss = 0.00081, d_fk_loss = 0.00011, g_adv_loss = 0.98093, g_l1_loss = 0.34834, time/batch = 89.10876, mtime/batch = 90.38873\n",
      "102/360 (epoch 34), d_rl_loss = 0.00061, d_fk_loss = 0.00001, g_adv_loss = 1.01532, g_l1_loss = 0.30937, time/batch = 89.24390, mtime/batch = 90.37762\n",
      "103/360 (epoch 34), d_rl_loss = 0.00057, d_fk_loss = 0.00001, g_adv_loss = 0.98907, g_l1_loss = 0.27634, time/batch = 90.06043, mtime/batch = 90.37457\n",
      "104/360 (epoch 34), d_rl_loss = 0.00048, d_fk_loss = 0.00004, g_adv_loss = 1.01992, g_l1_loss = 0.24337, time/batch = 90.40756, mtime/batch = 90.37488\n",
      "105/360 (epoch 35), d_rl_loss = 0.00057, d_fk_loss = 0.00005, g_adv_loss = 0.98549, g_l1_loss = 0.28913, time/batch = 90.08885, mtime/batch = 90.37218\n",
      "106/360 (epoch 35), d_rl_loss = 0.00058, d_fk_loss = 0.00011, g_adv_loss = 0.97239, g_l1_loss = 0.30433, time/batch = 90.75491, mtime/batch = 90.37576\n",
      "107/360 (epoch 35), d_rl_loss = 0.00036, d_fk_loss = 0.00009, g_adv_loss = 1.00448, g_l1_loss = 0.31603, time/batch = 90.33071, mtime/batch = 90.37534\n",
      "108/360 (epoch 36), d_rl_loss = 0.00042, d_fk_loss = 0.01243, g_adv_loss = 1.01731, g_l1_loss = 0.25270, time/batch = 90.47312, mtime/batch = 90.37624\n",
      "109/360 (epoch 36), d_rl_loss = 0.05241, d_fk_loss = 0.00007, g_adv_loss = 0.90065, g_l1_loss = 0.27457, time/batch = 89.15558, mtime/batch = 90.36514\n",
      "110/360 (epoch 36), d_rl_loss = 0.01317, d_fk_loss = 0.00241, g_adv_loss = 1.06550, g_l1_loss = 0.26828, time/batch = 90.41892, mtime/batch = 90.36563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/360 (epoch 37), d_rl_loss = 0.00097, d_fk_loss = 0.00210, g_adv_loss = 0.90874, g_l1_loss = 0.28506, time/batch = 90.04352, mtime/batch = 90.36275\n",
      "112/360 (epoch 37), d_rl_loss = 0.00039, d_fk_loss = 0.00228, g_adv_loss = 1.08457, g_l1_loss = 0.24713, time/batch = 89.84812, mtime/batch = 90.35820\n",
      "113/360 (epoch 37), d_rl_loss = 0.00020, d_fk_loss = 0.00096, g_adv_loss = 1.01220, g_l1_loss = 0.27156, time/batch = 89.93551, mtime/batch = 90.35449\n",
      "114/360 (epoch 38), d_rl_loss = 0.00014, d_fk_loss = 0.00006, g_adv_loss = 0.98768, g_l1_loss = 0.28420, time/batch = 89.98853, mtime/batch = 90.35131\n",
      "115/360 (epoch 38), d_rl_loss = 0.00014, d_fk_loss = 0.00160, g_adv_loss = 1.00353, g_l1_loss = 0.30131, time/batch = 90.02056, mtime/batch = 90.34846\n",
      "116/360 (epoch 38), d_rl_loss = 0.00089, d_fk_loss = 0.00025, g_adv_loss = 0.98088, g_l1_loss = 0.27437, time/batch = 89.93845, mtime/batch = 90.34495\n",
      "117/360 (epoch 39), d_rl_loss = 0.00024, d_fk_loss = 0.00008, g_adv_loss = 1.00272, g_l1_loss = 0.25111, time/batch = 90.07187, mtime/batch = 90.34264\n",
      "118/360 (epoch 39), d_rl_loss = 0.00018, d_fk_loss = 0.00004, g_adv_loss = 1.00624, g_l1_loss = 0.30186, time/batch = 90.84232, mtime/batch = 90.34684\n",
      "119/360 (epoch 39), d_rl_loss = 0.00025, d_fk_loss = 0.00004, g_adv_loss = 0.99786, g_l1_loss = 0.24816, time/batch = 90.13842, mtime/batch = 90.34510\n",
      "120/360 (epoch 40), d_rl_loss = 0.00044, d_fk_loss = 0.00008, g_adv_loss = 1.02288, g_l1_loss = 0.30782, time/batch = 90.06203, mtime/batch = 90.34276\n",
      "121/360 (epoch 40), d_rl_loss = 0.00059, d_fk_loss = 0.00021, g_adv_loss = 0.98251, g_l1_loss = 0.27309, time/batch = 90.52775, mtime/batch = 90.34428\n",
      "122/360 (epoch 40), d_rl_loss = 0.00070, d_fk_loss = 0.00034, g_adv_loss = 1.02695, g_l1_loss = 0.25486, time/batch = 90.76684, mtime/batch = 90.34771\n",
      "123/360 (epoch 41), d_rl_loss = 0.00072, d_fk_loss = 0.00072, g_adv_loss = 0.93342, g_l1_loss = 0.26468, time/batch = 90.10608, mtime/batch = 90.34576\n",
      "124/360 (epoch 41), d_rl_loss = 0.00094, d_fk_loss = 0.00127, g_adv_loss = 1.05428, g_l1_loss = 0.27814, time/batch = 90.68776, mtime/batch = 90.34850\n",
      "125/360 (epoch 41), d_rl_loss = 0.00126, d_fk_loss = 0.00044, g_adv_loss = 0.99045, g_l1_loss = 0.25487, time/batch = 90.00521, mtime/batch = 90.34578\n",
      "126/360 (epoch 42), d_rl_loss = 0.00132, d_fk_loss = 0.00004, g_adv_loss = 0.99165, g_l1_loss = 0.25001, time/batch = 90.69679, mtime/batch = 90.34854\n",
      "127/360 (epoch 42), d_rl_loss = 0.00080, d_fk_loss = 0.00021, g_adv_loss = 1.00936, g_l1_loss = 0.27081, time/batch = 88.57227, mtime/batch = 90.33466\n",
      "128/360 (epoch 42), d_rl_loss = 0.00081, d_fk_loss = 0.00021, g_adv_loss = 0.97713, g_l1_loss = 0.27709, time/batch = 90.80647, mtime/batch = 90.33832\n",
      "129/360 (epoch 43), d_rl_loss = 0.00089, d_fk_loss = 0.00017, g_adv_loss = 1.00465, g_l1_loss = 0.25488, time/batch = 90.10864, mtime/batch = 90.33655\n",
      "130/360 (epoch 43), d_rl_loss = 0.00061, d_fk_loss = 0.00064, g_adv_loss = 1.00372, g_l1_loss = 0.26903, time/batch = 90.91675, mtime/batch = 90.34098\n",
      "131/360 (epoch 43), d_rl_loss = 0.00089, d_fk_loss = 0.00004, g_adv_loss = 1.00146, g_l1_loss = 0.30747, time/batch = 89.16988, mtime/batch = 90.33211\n",
      "132/360 (epoch 44), d_rl_loss = 0.00066, d_fk_loss = 0.00005, g_adv_loss = 1.01697, g_l1_loss = 0.25405, time/batch = 90.59402, mtime/batch = 90.33408\n",
      "133/360 (epoch 44), d_rl_loss = 0.00046, d_fk_loss = 0.00037, g_adv_loss = 1.01135, g_l1_loss = 0.25351, time/batch = 89.57816, mtime/batch = 90.32844\n",
      "134/360 (epoch 44), d_rl_loss = 0.00028, d_fk_loss = 0.00008, g_adv_loss = 1.01501, g_l1_loss = 0.28838, time/batch = 90.91101, mtime/batch = 90.33275\n",
      "135/360 (epoch 45), d_rl_loss = 0.00023, d_fk_loss = 0.00023, g_adv_loss = 0.97430, g_l1_loss = 0.25279, time/batch = 90.32827, mtime/batch = 90.33272\n",
      "136/360 (epoch 45), d_rl_loss = 0.00035, d_fk_loss = 0.00025, g_adv_loss = 1.03423, g_l1_loss = 0.26267, time/batch = 90.86158, mtime/batch = 90.33658\n",
      "137/360 (epoch 45), d_rl_loss = 0.00033, d_fk_loss = 0.00019, g_adv_loss = 0.97883, g_l1_loss = 0.28900, time/batch = 90.26361, mtime/batch = 90.33605\n",
      "138/360 (epoch 46), d_rl_loss = 0.00016, d_fk_loss = 0.00015, g_adv_loss = 1.00682, g_l1_loss = 0.27897, time/batch = 90.57939, mtime/batch = 90.33780\n",
      "139/360 (epoch 46), d_rl_loss = 0.00020, d_fk_loss = 0.00057, g_adv_loss = 0.92650, g_l1_loss = 0.26115, time/batch = 90.26284, mtime/batch = 90.33727\n",
      "140/360 (epoch 46), d_rl_loss = 0.00042, d_fk_loss = 0.00119, g_adv_loss = 1.05902, g_l1_loss = 0.26464, time/batch = 90.87526, mtime/batch = 90.34108\n",
      "141/360 (epoch 47), d_rl_loss = 0.00050, d_fk_loss = 0.00031, g_adv_loss = 0.98699, g_l1_loss = 0.25431, time/batch = 90.29020, mtime/batch = 90.34072\n",
      "142/360 (epoch 47), d_rl_loss = 0.00035, d_fk_loss = 0.00001, g_adv_loss = 1.00665, g_l1_loss = 0.33013, time/batch = 90.86390, mtime/batch = 90.34438\n",
      "143/360 (epoch 47), d_rl_loss = 0.00056, d_fk_loss = 0.00025, g_adv_loss = 1.02389, g_l1_loss = 0.29921, time/batch = 90.32649, mtime/batch = 90.34426\n",
      "144/360 (epoch 48), d_rl_loss = 0.00076, d_fk_loss = 0.00027, g_adv_loss = 0.98369, g_l1_loss = 0.28363, time/batch = 90.81647, mtime/batch = 90.34752\n",
      "145/360 (epoch 48), d_rl_loss = 0.00038, d_fk_loss = 0.00010, g_adv_loss = 1.00489, g_l1_loss = 0.24444, time/batch = 90.28196, mtime/batch = 90.34707\n",
      "146/360 (epoch 48), d_rl_loss = 0.00031, d_fk_loss = 0.00003, g_adv_loss = 0.99475, g_l1_loss = 0.24909, time/batch = 90.92989, mtime/batch = 90.35103\n",
      "147/360 (epoch 49), d_rl_loss = 0.00024, d_fk_loss = 0.00003, g_adv_loss = 0.99592, g_l1_loss = 0.26690, time/batch = 90.35849, mtime/batch = 90.35108\n",
      "148/360 (epoch 49), d_rl_loss = 0.00019, d_fk_loss = 0.00009, g_adv_loss = 0.99330, g_l1_loss = 0.25231, time/batch = 90.47223, mtime/batch = 90.35190\n",
      "149/360 (epoch 49), d_rl_loss = 0.00052, d_fk_loss = 0.00009, g_adv_loss = 0.95300, g_l1_loss = 0.28963, time/batch = 91.01073, mtime/batch = 90.35629\n",
      "w0 max: 0.0172738227993 min: -0.0197124052793\n",
      "w1 max: 0.0250001251698 min: -0.0255768485367\n",
      "w2 max: 0.0278179943562 min: -0.0306218061596\n",
      "w3 max: 0.0478930622339 min: -0.0428773723543\n",
      "w4 max: 0.0451436154544 min: -0.055484790355\n",
      "w5 max: 0.0598455667496 min: -0.0538332499564\n",
      "w6 max: 0.0325908996165 min: -0.0377503186464\n",
      "w7 max: 0.13049146533 min: -0.101254299283\n",
      "w8 max: 0.051243212074 min: -0.0481401607394\n",
      "w9 max: 0.0987931787968 min: -0.111098647118\n",
      "w10 max: 0.0888411253691 min: -0.0993956699967\n",
      "w11 max: 0.126568078995 min: -0.0963566377759\n",
      "w12 max: 0.0651916339993 min: -0.0772593840957\n",
      "w13 max: 0.096720688045 min: -0.107410438359\n",
      "w14 max: 0.11904180795 min: -0.0916956067085\n",
      "w15 max: 0.0204779915512 min: -0.0194866620004\n",
      "w16 max: 0.0269103441387 min: -0.0326888784766\n",
      "w17 max: 0.0147289084271 min: -0.0163437332958\n",
      "w18 max: 0.0512842349708 min: -0.0475003905594\n",
      "w19 max: 0.114341303706 min: -0.0952140763402\n",
      "150/360 (epoch 50), d_rl_loss = 0.00142, d_fk_loss = 0.00029, g_adv_loss = 1.05137, g_l1_loss = 0.22735, time/batch = 90.82487, mtime/batch = 90.35939\n",
      "151/360 (epoch 50), d_rl_loss = 0.00181, d_fk_loss = 0.00027, g_adv_loss = 0.98535, g_l1_loss = 0.27533, time/batch = 90.37349, mtime/batch = 90.35948\n",
      "152/360 (epoch 50), d_rl_loss = 0.00212, d_fk_loss = 0.00022, g_adv_loss = 1.01351, g_l1_loss = 0.27197, time/batch = 90.75051, mtime/batch = 90.36204\n",
      "153/360 (epoch 51), d_rl_loss = 0.00134, d_fk_loss = 0.00025, g_adv_loss = 0.97099, g_l1_loss = 0.27148, time/batch = 90.32813, mtime/batch = 90.36182\n",
      "154/360 (epoch 51), d_rl_loss = 0.00079, d_fk_loss = 0.00044, g_adv_loss = 1.01296, g_l1_loss = 0.24579, time/batch = 91.42209, mtime/batch = 90.36866\n",
      "155/360 (epoch 51), d_rl_loss = 0.00075, d_fk_loss = 0.00020, g_adv_loss = 0.97737, g_l1_loss = 0.24209, time/batch = 90.45178, mtime/batch = 90.36919\n",
      "156/360 (epoch 52), d_rl_loss = 0.00040, d_fk_loss = 0.00009, g_adv_loss = 1.00214, g_l1_loss = 0.25624, time/batch = 90.81546, mtime/batch = 90.37203\n",
      "157/360 (epoch 52), d_rl_loss = 0.00035, d_fk_loss = 0.00002, g_adv_loss = 0.99299, g_l1_loss = 0.25711, time/batch = 90.58041, mtime/batch = 90.37335\n",
      "158/360 (epoch 52), d_rl_loss = 0.00042, d_fk_loss = 0.00001, g_adv_loss = 0.99373, g_l1_loss = 0.24568, time/batch = 91.05263, mtime/batch = 90.37763\n",
      "159/360 (epoch 53), d_rl_loss = 0.00026, d_fk_loss = 0.00001, g_adv_loss = 0.99137, g_l1_loss = 0.25225, time/batch = 90.00639, mtime/batch = 90.37531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/360 (epoch 53), d_rl_loss = 0.00022, d_fk_loss = 0.00005, g_adv_loss = 1.00835, g_l1_loss = 0.23225, time/batch = 90.87349, mtime/batch = 90.37840\n",
      "161/360 (epoch 53), d_rl_loss = 0.00037, d_fk_loss = 0.00007, g_adv_loss = 0.99272, g_l1_loss = 0.23709, time/batch = 90.20195, mtime/batch = 90.37731\n",
      "162/360 (epoch 54), d_rl_loss = 0.00037, d_fk_loss = 0.00003, g_adv_loss = 0.99104, g_l1_loss = 0.25181, time/batch = 90.78331, mtime/batch = 90.37980\n",
      "163/360 (epoch 54), d_rl_loss = 0.00031, d_fk_loss = 0.00003, g_adv_loss = 0.97206, g_l1_loss = 0.23078, time/batch = 90.36379, mtime/batch = 90.37970\n",
      "164/360 (epoch 54), d_rl_loss = 0.00031, d_fk_loss = 0.00009, g_adv_loss = 1.02322, g_l1_loss = 0.23787, time/batch = 91.06587, mtime/batch = 90.38386\n",
      "165/360 (epoch 55), d_rl_loss = 0.00040, d_fk_loss = 0.00011, g_adv_loss = 0.97542, g_l1_loss = 0.22975, time/batch = 90.55857, mtime/batch = 90.38491\n",
      "166/360 (epoch 55), d_rl_loss = 0.00081, d_fk_loss = 0.00004, g_adv_loss = 1.00636, g_l1_loss = 0.28606, time/batch = 90.83774, mtime/batch = 90.38763\n",
      "167/360 (epoch 55), d_rl_loss = 0.00036, d_fk_loss = 0.00013, g_adv_loss = 0.97258, g_l1_loss = 0.27714, time/batch = 89.09518, mtime/batch = 90.37993\n",
      "168/360 (epoch 56), d_rl_loss = 0.00028, d_fk_loss = 0.00076, g_adv_loss = 0.95494, g_l1_loss = 0.76156, time/batch = 91.06202, mtime/batch = 90.38397\n",
      "169/360 (epoch 56), d_rl_loss = 0.00106, d_fk_loss = 0.00014, g_adv_loss = 1.03298, g_l1_loss = 0.36189, time/batch = 90.35941, mtime/batch = 90.38382\n",
      "170/360 (epoch 56), d_rl_loss = 0.00137, d_fk_loss = 0.00045, g_adv_loss = 0.95205, g_l1_loss = 0.26280, time/batch = 91.00660, mtime/batch = 90.38747\n",
      "171/360 (epoch 57), d_rl_loss = 0.01207, d_fk_loss = 0.00052, g_adv_loss = 0.91209, g_l1_loss = 0.27591, time/batch = 90.39605, mtime/batch = 90.38752\n",
      "172/360 (epoch 57), d_rl_loss = 0.00449, d_fk_loss = 0.01975, g_adv_loss = 1.05579, g_l1_loss = 0.27946, time/batch = 90.61921, mtime/batch = 90.38886\n",
      "173/360 (epoch 57), d_rl_loss = 0.00658, d_fk_loss = 0.00104, g_adv_loss = 0.96056, g_l1_loss = 0.27161, time/batch = 90.53688, mtime/batch = 90.38971\n",
      "174/360 (epoch 58), d_rl_loss = 0.00139, d_fk_loss = 0.00047, g_adv_loss = 1.05002, g_l1_loss = 0.22819, time/batch = 90.96733, mtime/batch = 90.39301\n",
      "175/360 (epoch 58), d_rl_loss = 0.00060, d_fk_loss = 0.00059, g_adv_loss = 0.96286, g_l1_loss = 0.22969, time/batch = 90.01722, mtime/batch = 90.39087\n",
      "176/360 (epoch 58), d_rl_loss = 0.00055, d_fk_loss = 0.00025, g_adv_loss = 1.02290, g_l1_loss = 0.25139, time/batch = 90.78633, mtime/batch = 90.39311\n",
      "177/360 (epoch 59), d_rl_loss = 0.00037, d_fk_loss = 0.00015, g_adv_loss = 0.98632, g_l1_loss = 0.24857, time/batch = 90.57593, mtime/batch = 90.39413\n",
      "178/360 (epoch 59), d_rl_loss = 0.00030, d_fk_loss = 0.00006, g_adv_loss = 0.99811, g_l1_loss = 0.23266, time/batch = 90.96002, mtime/batch = 90.39729\n",
      "179/360 (epoch 59), d_rl_loss = 0.00019, d_fk_loss = 0.00005, g_adv_loss = 0.99718, g_l1_loss = 0.24471, time/batch = 90.08783, mtime/batch = 90.39558\n",
      "180/360 (epoch 60), d_rl_loss = 0.00014, d_fk_loss = 0.00006, g_adv_loss = 0.99711, g_l1_loss = 0.23734, time/batch = 91.04298, mtime/batch = 90.39915\n",
      "181/360 (epoch 60), d_rl_loss = 0.00009, d_fk_loss = 0.00008, g_adv_loss = 1.01368, g_l1_loss = 0.24950, time/batch = 90.14811, mtime/batch = 90.39777\n",
      "182/360 (epoch 60), d_rl_loss = 0.00006, d_fk_loss = 0.00009, g_adv_loss = 1.00820, g_l1_loss = 0.24792, time/batch = 90.80485, mtime/batch = 90.40000\n",
      "183/360 (epoch 61), d_rl_loss = 0.00005, d_fk_loss = 0.00006, g_adv_loss = 0.97248, g_l1_loss = 0.26995, time/batch = 90.06096, mtime/batch = 90.39815\n",
      "184/360 (epoch 61), d_rl_loss = 0.00013, d_fk_loss = 0.00019, g_adv_loss = 1.03164, g_l1_loss = 0.27189, time/batch = 90.92937, mtime/batch = 90.40103\n",
      "185/360 (epoch 61), d_rl_loss = 0.00060, d_fk_loss = 0.00013, g_adv_loss = 0.98843, g_l1_loss = 0.24609, time/batch = 90.61476, mtime/batch = 90.40218\n",
      "186/360 (epoch 62), d_rl_loss = 0.00134, d_fk_loss = 0.00005, g_adv_loss = 1.00806, g_l1_loss = 0.29102, time/batch = 90.39893, mtime/batch = 90.40216\n",
      "187/360 (epoch 62), d_rl_loss = 0.00171, d_fk_loss = 0.00011, g_adv_loss = 0.97890, g_l1_loss = 0.25105, time/batch = 90.80129, mtime/batch = 90.40428\n",
      "188/360 (epoch 62), d_rl_loss = 0.00149, d_fk_loss = 0.00023, g_adv_loss = 1.01590, g_l1_loss = 0.24725, time/batch = 90.79576, mtime/batch = 90.40635\n",
      "189/360 (epoch 63), d_rl_loss = 0.00095, d_fk_loss = 0.00008, g_adv_loss = 0.98789, g_l1_loss = 0.26445, time/batch = 90.97938, mtime/batch = 90.40937\n",
      "190/360 (epoch 63), d_rl_loss = 0.00052, d_fk_loss = 0.00006, g_adv_loss = 0.99511, g_l1_loss = 0.21996, time/batch = 89.96709, mtime/batch = 90.40705\n",
      "191/360 (epoch 63), d_rl_loss = 0.00030, d_fk_loss = 0.00426, g_adv_loss = 1.03163, g_l1_loss = 0.20222, time/batch = 90.52878, mtime/batch = 90.40769\n",
      "192/360 (epoch 64), d_rl_loss = 0.00091, d_fk_loss = 0.00057, g_adv_loss = 0.91465, g_l1_loss = 0.23651, time/batch = 90.08781, mtime/batch = 90.40603\n",
      "193/360 (epoch 64), d_rl_loss = 0.00089, d_fk_loss = 0.00157, g_adv_loss = 1.07937, g_l1_loss = 0.25777, time/batch = 90.76426, mtime/batch = 90.40788\n",
      "194/360 (epoch 64), d_rl_loss = 0.00004, d_fk_loss = 0.00100, g_adv_loss = 0.96879, g_l1_loss = 0.24309, time/batch = 90.37883, mtime/batch = 90.40773\n",
      "195/360 (epoch 65), d_rl_loss = 0.00074, d_fk_loss = 0.00028, g_adv_loss = 1.01833, g_l1_loss = 0.22603, time/batch = 90.53689, mtime/batch = 90.40839\n",
      "196/360 (epoch 65), d_rl_loss = 0.00012, d_fk_loss = 0.00014, g_adv_loss = 0.98860, g_l1_loss = 0.25648, time/batch = 89.96431, mtime/batch = 90.40613\n",
      "197/360 (epoch 65), d_rl_loss = 0.00014, d_fk_loss = 0.00023, g_adv_loss = 1.01455, g_l1_loss = 0.21934, time/batch = 90.32082, mtime/batch = 90.40570\n",
      "198/360 (epoch 66), d_rl_loss = 0.00026, d_fk_loss = 0.00010, g_adv_loss = 0.99956, g_l1_loss = 0.25391, time/batch = 90.13682, mtime/batch = 90.40435\n",
      "199/360 (epoch 66), d_rl_loss = 0.00032, d_fk_loss = 0.00002, g_adv_loss = 0.99896, g_l1_loss = 0.26312, time/batch = 90.65673, mtime/batch = 90.40561\n",
      "w0 max: 0.0151460282505 min: -0.0153100341558\n",
      "w1 max: 0.0248336941004 min: -0.028953557834\n",
      "w2 max: 0.0266272071749 min: -0.0321065075696\n",
      "w3 max: 0.044184897095 min: -0.039191108197\n",
      "w4 max: 0.0426764748991 min: -0.0547788962722\n",
      "w5 max: 0.055513817817 min: -0.0510260276496\n",
      "w6 max: 0.027450574562 min: -0.0343971587718\n",
      "w7 max: 0.114782571793 min: -0.108004905283\n",
      "w8 max: 0.0451920293272 min: -0.0424332432449\n",
      "w9 max: 0.0901498645544 min: -0.10432446748\n",
      "w10 max: 0.0807119682431 min: -0.0955709144473\n",
      "w11 max: 0.115657120943 min: -0.0915179178119\n",
      "w12 max: 0.0614954456687 min: -0.0758903250098\n",
      "w13 max: 0.0874227955937 min: -0.102280572057\n",
      "w14 max: 0.10623113066 min: -0.0920277759433\n",
      "w15 max: 0.0152129773051 min: -0.0165702681988\n",
      "w16 max: 0.0239210966974 min: -0.0333624072373\n",
      "w17 max: 0.0127963265404 min: -0.0127690583467\n",
      "w18 max: 0.0463327132165 min: -0.0440209470689\n",
      "w19 max: 0.108318701386 min: -0.093115709722\n",
      "200/360 (epoch 66), d_rl_loss = 0.00016, d_fk_loss = 0.00004, g_adv_loss = 0.98358, g_l1_loss = 0.23358, time/batch = 90.23081, mtime/batch = 90.40474\n",
      "201/360 (epoch 67), d_rl_loss = 0.00011, d_fk_loss = 0.00004, g_adv_loss = 1.00523, g_l1_loss = 0.22295, time/batch = 90.65232, mtime/batch = 90.40597\n",
      "202/360 (epoch 67), d_rl_loss = 0.00017, d_fk_loss = 0.00002, g_adv_loss = 1.00102, g_l1_loss = 0.25093, time/batch = 90.05625, mtime/batch = 90.40424\n",
      "203/360 (epoch 67), d_rl_loss = 0.00028, d_fk_loss = 0.00010, g_adv_loss = 1.00503, g_l1_loss = 0.21019, time/batch = 90.32407, mtime/batch = 90.40385\n",
      "204/360 (epoch 68), d_rl_loss = 0.00049, d_fk_loss = 0.00059, g_adv_loss = 0.88236, g_l1_loss = 0.27065, time/batch = 90.11835, mtime/batch = 90.40246\n",
      "205/360 (epoch 68), d_rl_loss = 0.00062, d_fk_loss = 0.00429, g_adv_loss = 1.15897, g_l1_loss = 0.28350, time/batch = 90.37437, mtime/batch = 90.40232\n",
      "206/360 (epoch 68), d_rl_loss = 0.00121, d_fk_loss = 0.00501, g_adv_loss = 0.93511, g_l1_loss = 0.30949, time/batch = 89.98216, mtime/batch = 90.40029\n",
      "207/360 (epoch 69), d_rl_loss = 0.00237, d_fk_loss = 0.00113, g_adv_loss = 1.02082, g_l1_loss = 0.26639, time/batch = 90.48632, mtime/batch = 90.40071\n",
      "208/360 (epoch 69), d_rl_loss = 0.00145, d_fk_loss = 0.00002, g_adv_loss = 1.00422, g_l1_loss = 0.28483, time/batch = 90.12954, mtime/batch = 90.39941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/360 (epoch 69), d_rl_loss = 0.00052, d_fk_loss = 0.00003, g_adv_loss = 0.98986, g_l1_loss = 0.24040, time/batch = 90.43585, mtime/batch = 90.39958\n",
      "210/360 (epoch 70), d_rl_loss = 0.00027, d_fk_loss = 0.01331, g_adv_loss = 1.00014, g_l1_loss = 0.24599, time/batch = 89.96816, mtime/batch = 90.39754\n",
      "211/360 (epoch 70), d_rl_loss = 0.00689, d_fk_loss = 0.00004, g_adv_loss = 1.01006, g_l1_loss = 0.22154, time/batch = 90.54755, mtime/batch = 90.39825\n",
      "220/360 (epoch 73), d_rl_loss = 0.00004, d_fk_loss = 0.00003, g_adv_loss = 1.01100, g_l1_loss = 0.23427, time/batch = 90.04212, mtime/batch = 90.38509\n",
      "221/360 (epoch 73), d_rl_loss = 0.00007, d_fk_loss = 0.00003, g_adv_loss = 0.98749, g_l1_loss = 0.23789, time/batch = 90.55154, mtime/batch = 90.38584\n",
      "222/360 (epoch 74), d_rl_loss = 0.00007, d_fk_loss = 0.00004, g_adv_loss = 1.00386, g_l1_loss = 0.20456, time/batch = 90.12750, mtime/batch = 90.38468\n",
      "223/360 (epoch 74), d_rl_loss = 0.00004, d_fk_loss = 0.00007, g_adv_loss = 0.98047, g_l1_loss = 0.22809, time/batch = 90.74847, mtime/batch = 90.38630\n",
      "224/360 (epoch 74), d_rl_loss = 0.00005, d_fk_loss = 0.00014, g_adv_loss = 1.03143, g_l1_loss = 0.24128, time/batch = 90.27510, mtime/batch = 90.38581\n",
      "225/360 (epoch 75), d_rl_loss = 0.00013, d_fk_loss = 0.00029, g_adv_loss = 0.97454, g_l1_loss = 0.23429, time/batch = 90.82044, mtime/batch = 90.38773\n",
      "226/360 (epoch 75), d_rl_loss = 0.00060, d_fk_loss = 0.00019, g_adv_loss = 1.03257, g_l1_loss = 0.22818, time/batch = 90.14521, mtime/batch = 90.38666\n",
      "227/360 (epoch 75), d_rl_loss = 0.00160, d_fk_loss = 0.00018, g_adv_loss = 0.97883, g_l1_loss = 0.23085, time/batch = 90.78277, mtime/batch = 90.38840\n",
      "228/360 (epoch 76), d_rl_loss = 0.00246, d_fk_loss = 0.00015, g_adv_loss = 1.00259, g_l1_loss = 0.24934, time/batch = 90.01037, mtime/batch = 90.38675\n",
      "229/360 (epoch 76), d_rl_loss = 0.00215, d_fk_loss = 0.00007, g_adv_loss = 1.00868, g_l1_loss = 0.28248, time/batch = 90.63326, mtime/batch = 90.38782\n",
      "230/360 (epoch 76), d_rl_loss = 0.00134, d_fk_loss = 0.00002, g_adv_loss = 0.99737, g_l1_loss = 0.23970, time/batch = 90.24531, mtime/batch = 90.38721\n",
      "231/360 (epoch 77), d_rl_loss = 0.00056, d_fk_loss = 0.00001, g_adv_loss = 0.98064, g_l1_loss = 0.21884, time/batch = 90.60831, mtime/batch = 90.38816\n",
      "232/360 (epoch 77), d_rl_loss = 0.00043, d_fk_loss = 0.00008, g_adv_loss = 1.00380, g_l1_loss = 0.24826, time/batch = 90.46452, mtime/batch = 90.38849\n",
      "233/360 (epoch 77), d_rl_loss = 0.00028, d_fk_loss = 0.00007, g_adv_loss = 0.97288, g_l1_loss = 0.23077, time/batch = 90.84679, mtime/batch = 90.39044\n",
      "234/360 (epoch 78), d_rl_loss = 0.00017, d_fk_loss = 0.00024, g_adv_loss = 1.03140, g_l1_loss = 0.22285, time/batch = 90.10635, mtime/batch = 90.38924\n",
      "235/360 (epoch 78), d_rl_loss = 0.00016, d_fk_loss = 0.00028, g_adv_loss = 0.97041, g_l1_loss = 0.23916, time/batch = 90.89316, mtime/batch = 90.39137\n",
      "236/360 (epoch 78), d_rl_loss = 0.00016, d_fk_loss = 0.00024, g_adv_loss = 1.02162, g_l1_loss = 0.22943, time/batch = 90.26471, mtime/batch = 90.39084\n",
      "237/360 (epoch 79), d_rl_loss = 0.00027, d_fk_loss = 0.00007, g_adv_loss = 0.98704, g_l1_loss = 0.20818, time/batch = 90.62976, mtime/batch = 90.39184\n",
      "238/360 (epoch 79), d_rl_loss = 0.00036, d_fk_loss = 0.00001, g_adv_loss = 0.98697, g_l1_loss = 0.24073, time/batch = 90.17942, mtime/batch = 90.39095\n",
      "239/360 (epoch 79), d_rl_loss = 0.00027, d_fk_loss = 0.00005, g_adv_loss = 1.01701, g_l1_loss = 0.26039, time/batch = 89.36702, mtime/batch = 90.38669\n",
      "240/360 (epoch 80), d_rl_loss = 0.00023, d_fk_loss = 0.00011, g_adv_loss = 1.00271, g_l1_loss = 0.20556, time/batch = 89.48509, mtime/batch = 90.38294\n",
      "241/360 (epoch 80), d_rl_loss = 0.00012, d_fk_loss = 0.00004, g_adv_loss = 0.98731, g_l1_loss = 0.22332, time/batch = 90.58695, mtime/batch = 90.38379\n",
      "242/360 (epoch 80), d_rl_loss = 0.00021, d_fk_loss = 0.00004, g_adv_loss = 1.00971, g_l1_loss = 0.23325, time/batch = 90.16087, mtime/batch = 90.38287\n",
      "243/360 (epoch 81), d_rl_loss = 0.00064, d_fk_loss = 0.00001, g_adv_loss = 1.01070, g_l1_loss = 0.22437, time/batch = 90.60691, mtime/batch = 90.38379\n",
      "244/360 (epoch 81), d_rl_loss = 0.00069, d_fk_loss = 0.00001, g_adv_loss = 0.98741, g_l1_loss = 0.23841, time/batch = 90.05446, mtime/batch = 90.38244\n",
      "245/360 (epoch 81), d_rl_loss = 0.00052, d_fk_loss = 0.00002, g_adv_loss = 1.00819, g_l1_loss = 0.23554, time/batch = 90.74805, mtime/batch = 90.38393\n",
      "246/360 (epoch 82), d_rl_loss = 0.00053, d_fk_loss = 0.00004, g_adv_loss = 0.99617, g_l1_loss = 0.24293, time/batch = 89.99820, mtime/batch = 90.38237\n",
      "247/360 (epoch 82), d_rl_loss = 0.00059, d_fk_loss = 0.00000, g_adv_loss = 1.00646, g_l1_loss = 0.26547, time/batch = 90.59505, mtime/batch = 90.38323\n",
      "248/360 (epoch 82), d_rl_loss = 0.00071, d_fk_loss = 0.00002, g_adv_loss = 0.98338, g_l1_loss = 0.23890, time/batch = 90.10193, mtime/batch = 90.38210\n",
      "249/360 (epoch 83), d_rl_loss = 0.00101, d_fk_loss = 0.00009, g_adv_loss = 1.01146, g_l1_loss = 0.22509, time/batch = 90.56296, mtime/batch = 90.38282\n",
      "w0 max: 0.0150235015899 min: -0.0163368936628\n",
      "w1 max: 0.0278360117227 min: -0.0324844680727\n",
      "w2 max: 0.0272987149656 min: -0.0339062996209\n",
      "w3 max: 0.0465450808406 min: -0.0424233563244\n",
      "w4 max: 0.0438855588436 min: -0.057886492461\n",
      "w5 max: 0.0554043315351 min: -0.0536001734436\n",
      "w6 max: 0.0305480062962 min: -0.0346660912037\n",
      "w7 max: 0.120502069592 min: -0.108675085008\n",
      "w8 max: 0.0468109808862 min: -0.0450321063399\n",
      "w9 max: 0.0930416956544 min: -0.108959972858\n",
      "w10 max: 0.0834934040904 min: -0.0964902564883\n",
      "w11 max: 0.115788757801 min: -0.0932566747069\n",
      "w12 max: 0.0611538290977 min: -0.0769870728254\n",
      "w13 max: 0.0891712158918 min: -0.104532621801\n",
      "w14 max: 0.111880205572 min: -0.0945213884115\n",
      "w15 max: 0.0154652027413 min: -0.0170742422342\n",
      "w16 max: 0.0260737538338 min: -0.034315019846\n",
      "w17 max: 0.0121862255037 min: -0.0154584059492\n",
      "w18 max: 0.0493172369897 min: -0.0467685721815\n",
      "w19 max: 0.100133888423 min: -0.0903112888336\n",
      "250/360 (epoch 83), d_rl_loss = 0.00121, d_fk_loss = 0.00023, g_adv_loss = 0.94870, g_l1_loss = 0.25653, time/batch = 90.03912, mtime/batch = 90.38145\n",
      "251/360 (epoch 83), d_rl_loss = 0.00103, d_fk_loss = 0.00062, g_adv_loss = 1.04563, g_l1_loss = 0.21640, time/batch = 90.64315, mtime/batch = 90.38249\n",
      "252/360 (epoch 84), d_rl_loss = 0.00047, d_fk_loss = 0.00031, g_adv_loss = 0.98121, g_l1_loss = 0.20879, time/batch = 89.94624, mtime/batch = 90.38076\n",
      "253/360 (epoch 84), d_rl_loss = 0.00039, d_fk_loss = 0.00006, g_adv_loss = 1.00363, g_l1_loss = 0.23483, time/batch = 90.55870, mtime/batch = 90.38147\n",
      "254/360 (epoch 84), d_rl_loss = 0.00049, d_fk_loss = 0.00009, g_adv_loss = 0.97267, g_l1_loss = 0.24944, time/batch = 90.08126, mtime/batch = 90.38029\n",
      "255/360 (epoch 85), d_rl_loss = 0.00035, d_fk_loss = 0.00021, g_adv_loss = 1.03135, g_l1_loss = 0.21138, time/batch = 90.55672, mtime/batch = 90.38098\n",
      "256/360 (epoch 85), d_rl_loss = 0.00028, d_fk_loss = 0.00007, g_adv_loss = 0.99661, g_l1_loss = 0.22830, time/batch = 90.17641, mtime/batch = 90.38018\n",
      "257/360 (epoch 85), d_rl_loss = 0.00026, d_fk_loss = 0.00001, g_adv_loss = 0.99585, g_l1_loss = 0.22221, time/batch = 90.32130, mtime/batch = 90.37995\n",
      "258/360 (epoch 86), d_rl_loss = 0.00024, d_fk_loss = 0.00007, g_adv_loss = 0.96878, g_l1_loss = 0.21124, time/batch = 90.14840, mtime/batch = 90.37906\n",
      "259/360 (epoch 86), d_rl_loss = 0.00040, d_fk_loss = 0.00031, g_adv_loss = 1.03750, g_l1_loss = 0.22698, time/batch = 90.58982, mtime/batch = 90.37987\n",
      "260/360 (epoch 86), d_rl_loss = 0.00056, d_fk_loss = 0.00020, g_adv_loss = 0.98063, g_l1_loss = 0.23768, time/batch = 90.10397, mtime/batch = 90.37881\n",
      "261/360 (epoch 87), d_rl_loss = 0.00048, d_fk_loss = 0.00006, g_adv_loss = 1.00189, g_l1_loss = 0.24019, time/batch = 90.54899, mtime/batch = 90.37946\n",
      "262/360 (epoch 87), d_rl_loss = 0.00037, d_fk_loss = 0.00000, g_adv_loss = 1.01021, g_l1_loss = 0.24821, time/batch = 89.96879, mtime/batch = 90.37790\n",
      "263/360 (epoch 87), d_rl_loss = 0.00032, d_fk_loss = 0.00004, g_adv_loss = 0.99735, g_l1_loss = 0.21510, time/batch = 90.59346, mtime/batch = 90.37872\n",
      "264/360 (epoch 88), d_rl_loss = 0.00020, d_fk_loss = 0.00008, g_adv_loss = 0.97096, g_l1_loss = 0.20662, time/batch = 90.05123, mtime/batch = 90.37748\n",
      "265/360 (epoch 88), d_rl_loss = 0.00015, d_fk_loss = 0.00016, g_adv_loss = 1.02804, g_l1_loss = 0.21777, time/batch = 90.58798, mtime/batch = 90.37827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/360 (epoch 88), d_rl_loss = 0.00009, d_fk_loss = 0.00069, g_adv_loss = 1.00549, g_l1_loss = 0.21539, time/batch = 90.05648, mtime/batch = 90.37707\n",
      "267/360 (epoch 89), d_rl_loss = 0.01558, d_fk_loss = 0.00017, g_adv_loss = 0.97563, g_l1_loss = 0.24921, time/batch = 90.37143, mtime/batch = 90.37705\n",
      "268/360 (epoch 89), d_rl_loss = 0.00127, d_fk_loss = 0.00030, g_adv_loss = 1.00713, g_l1_loss = 0.20667, time/batch = 89.29515, mtime/batch = 90.37302\n",
      "269/360 (epoch 89), d_rl_loss = 0.00072, d_fk_loss = 0.00104, g_adv_loss = 1.00324, g_l1_loss = 0.23981, time/batch = 90.44907, mtime/batch = 90.37331\n",
      "270/360 (epoch 90), d_rl_loss = 0.00042, d_fk_loss = 0.00005, g_adv_loss = 0.98689, g_l1_loss = 0.20743, time/batch = 90.07869, mtime/batch = 90.37222\n",
      "271/360 (epoch 90), d_rl_loss = 0.00084, d_fk_loss = 0.00016, g_adv_loss = 1.01918, g_l1_loss = 0.22985, time/batch = 90.70866, mtime/batch = 90.37346\n",
      "272/360 (epoch 90), d_rl_loss = 0.00155, d_fk_loss = 0.00014, g_adv_loss = 0.96965, g_l1_loss = 0.23260, time/batch = 89.93268, mtime/batch = 90.37184\n",
      "273/360 (epoch 91), d_rl_loss = 0.00204, d_fk_loss = 0.00016, g_adv_loss = 1.02508, g_l1_loss = 0.22301, time/batch = 89.97080, mtime/batch = 90.37038\n",
      "274/360 (epoch 91), d_rl_loss = 0.00136, d_fk_loss = 0.00014, g_adv_loss = 0.99399, g_l1_loss = 0.23015, time/batch = 90.09958, mtime/batch = 90.36939\n",
      "275/360 (epoch 91), d_rl_loss = 0.00077, d_fk_loss = 0.00005, g_adv_loss = 1.00530, g_l1_loss = 0.25057, time/batch = 90.57288, mtime/batch = 90.37013\n",
      "276/360 (epoch 92), d_rl_loss = 0.00038, d_fk_loss = 0.00758, g_adv_loss = 1.00771, g_l1_loss = 0.20386, time/batch = 90.00924, mtime/batch = 90.36883\n",
      "277/360 (epoch 92), d_rl_loss = 0.00973, d_fk_loss = 0.00001, g_adv_loss = 1.03282, g_l1_loss = 0.20531, time/batch = 90.59856, mtime/batch = 90.36965\n",
      "278/360 (epoch 92), d_rl_loss = 0.00055, d_fk_loss = 0.00017, g_adv_loss = 0.98261, g_l1_loss = 0.21228, time/batch = 89.91772, mtime/batch = 90.36803\n",
      "279/360 (epoch 93), d_rl_loss = 0.00015, d_fk_loss = 0.00004, g_adv_loss = 0.99365, g_l1_loss = 0.19575, time/batch = 90.35649, mtime/batch = 90.36799\n",
      "280/360 (epoch 93), d_rl_loss = 0.00012, d_fk_loss = 0.00006, g_adv_loss = 1.00015, g_l1_loss = 0.19838, time/batch = 90.32172, mtime/batch = 90.36783\n",
      "281/360 (epoch 93), d_rl_loss = 0.00013, d_fk_loss = 0.00006, g_adv_loss = 0.97035, g_l1_loss = 0.22586, time/batch = 90.47244, mtime/batch = 90.36820\n",
      "282/360 (epoch 94), d_rl_loss = 0.00036, d_fk_loss = 0.00014, g_adv_loss = 1.04420, g_l1_loss = 0.23903, time/batch = 90.20674, mtime/batch = 90.36763\n",
      "283/360 (epoch 94), d_rl_loss = 0.00088, d_fk_loss = 0.00047, g_adv_loss = 0.94310, g_l1_loss = 0.20424, time/batch = 90.40101, mtime/batch = 90.36775\n",
      "284/360 (epoch 94), d_rl_loss = 0.00102, d_fk_loss = 0.00071, g_adv_loss = 1.04062, g_l1_loss = 0.24135, time/batch = 90.00972, mtime/batch = 90.36649\n",
      "285/360 (epoch 95), d_rl_loss = 0.00086, d_fk_loss = 0.00058, g_adv_loss = 0.96433, g_l1_loss = 0.20431, time/batch = 90.52252, mtime/batch = 90.36704\n",
      "286/360 (epoch 95), d_rl_loss = 0.00063, d_fk_loss = 0.00031, g_adv_loss = 1.00897, g_l1_loss = 0.22643, time/batch = 90.22866, mtime/batch = 90.36655\n",
      "287/360 (epoch 95), d_rl_loss = 0.00037, d_fk_loss = 0.00009, g_adv_loss = 0.99441, g_l1_loss = 0.21923, time/batch = 90.70545, mtime/batch = 90.36773\n",
      "288/360 (epoch 96), d_rl_loss = 0.00017, d_fk_loss = 0.00003, g_adv_loss = 1.00788, g_l1_loss = 0.19645, time/batch = 90.05695, mtime/batch = 90.36665\n",
      "289/360 (epoch 96), d_rl_loss = 0.00011, d_fk_loss = 0.01633, g_adv_loss = 0.99049, g_l1_loss = 0.23300, time/batch = 90.60826, mtime/batch = 90.36749\n",
      "290/360 (epoch 96), d_rl_loss = 0.02353, d_fk_loss = 0.00018, g_adv_loss = 0.96095, g_l1_loss = 0.20918, time/batch = 89.95417, mtime/batch = 90.36607\n",
      "291/360 (epoch 97), d_rl_loss = 0.00274, d_fk_loss = 0.00066, g_adv_loss = 1.01670, g_l1_loss = 0.24519, time/batch = 90.61140, mtime/batch = 90.36691\n",
      "292/360 (epoch 97), d_rl_loss = 0.00151, d_fk_loss = 0.00011, g_adv_loss = 1.00384, g_l1_loss = 0.21966, time/batch = 90.17970, mtime/batch = 90.36627\n",
      "293/360 (epoch 97), d_rl_loss = 0.00041, d_fk_loss = 0.00006, g_adv_loss = 1.01386, g_l1_loss = 0.20000, time/batch = 90.55946, mtime/batch = 90.36693\n"
     ]
    }
   ],
   "source": [
    "!sh train_segan.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT NOISY WAV: record_noise/record_noise_28_clip_0.wav\n",
      "SAVE PATH: clean\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From main.py:122: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "Parsed arguments:  {'helpfull': <absl.app.HelpfullFlag object at 0x7f8d4ce42490>, 'deconv_type': <absl.flags._flag.Flag object at 0x7f8d4ce2ae10>, 'd_label_smooth': <absl.flags._flag.Flag object at 0x7f8d4ce2aa10>, 'z_depth': <absl.flags._flag.Flag object at 0x7f8d4ce2ac10>, 'help': <absl.app.HelpFlag object at 0x7f8d4ce42410>, 'showprefixforinfo': <absl.flags._flag.BooleanFlag object at 0x7f8d5ee9e450>, 'stderrthreshold': <absl.logging._StderrthresholdFlag object at 0x7f8d5ee9e3d0>, 'op_conversion_fallback_to_while_loop': <absl.flags._flag.BooleanFlag object at 0x7f8d5d5a55d0>, 'seed': <absl.flags._flag.Flag object at 0x7f8d4ce2a490>, 'test_randomize_ordering_seed': <absl.flags._flag.Flag object at 0x7f8d593bc1d0>, 'init_noise_std': <absl.flags._flag.Flag object at 0x7f8d4ce2aa90>, 'synthesis_path': <absl.flags._flag.Flag object at 0x7f8d4ce42150>, 'e2e_dataset': <absl.flags._flag.Flag object at 0x7f8d4ce421d0>, 'save_freq': <absl.flags._flag.Flag object at 0x7f8d4ce2a610>, 'alsologtostderr': <absl.flags._flag.BooleanFlag object at 0x7f8d5ee9e190>, 'logtostderr': <absl.flags._flag.BooleanFlag object at 0x7f8d5ee9e0d0>, 'g_type': <absl.flags._flag.Flag object at 0x7f8d4ce2ae90>, 'l1_remove_epoch': <absl.flags._flag.Flag object at 0x7f8d4ce2a790>, 'epoch': <absl.flags._flag.Flag object at 0x7f8d4ce2a510>, 'bias_D_conv': <absl.flags._flag.BooleanFlag object at 0x7f8d4ce2a850>, 'log_dir': <absl.flags._flag.Flag object at 0x7f8d5ee9e250>, 'save_path': <absl.flags._flag.Flag object at 0x7f8d4ce2ac90>, 'test_wav': <absl.flags._flag.Flag object at 0x7f8d4ce42350>, 'test_tmpdir': <absl.flags._flag.Flag object at 0x7f8d5939be90>, 'preemph': <absl.flags._flag.Flag object at 0x7f8d4ce420d0>, 'run_with_profiling': <absl.flags._flag.BooleanFlag object at 0x7f8d5ee9e890>, '?': <absl.app.HelpFlag object at 0x7f8d4ce42410>, 'run_with_pdb': <absl.flags._flag.BooleanFlag object at 0x7f8d5ee93510>, 'g_learning_rate': <absl.flags._flag.Flag object at 0x7f8d4ce2af10>, 'use_cprofile_for_profiling': <absl.flags._flag.BooleanFlag object at 0x7f8d5ee9e950>, 'helpshort': <absl.app.HelpshortFlag object at 0x7f8d4ce42450>, 'xml_output_file': <absl.flags._flag.Flag object at 0x7f8d593bc250>, 'z_dim': <absl.flags._flag.Flag object at 0x7f8d4ce2ab90>, 'batch_size': <absl.flags._flag.Flag object at 0x7f8d4ce2a590>, 'bias_downconv': <absl.flags._flag.BooleanFlag object at 0x7f8d4ce2a810>, 'denoise_epoch': <absl.flags._flag.Flag object at 0x7f8d4ce2a710>, 'canvas_size': <absl.flags._flag.Flag object at 0x7f8d4ce2a690>, 'noise_decay': <absl.flags._flag.Flag object at 0x7f8d4ce2a990>, 'g_nl': <absl.flags._flag.Flag object at 0x7f8d4ce2ad10>, 'test_random_seed': <absl.flags._flag.Flag object at 0x7f8d5939b5d0>, 'beta_1': <absl.flags._flag.Flag object at 0x7f8d4ce42050>, 'profile_file': <absl.flags._flag.Flag object at 0x7f8d5ee9e910>, 'd_learning_rate': <absl.flags._flag.Flag object at 0x7f8d4ce2af90>, 'verbosity': <absl.logging._VerbosityFlag object at 0x7f8d5ee9e290>, 'pdb_post_mortem': <absl.flags._flag.BooleanFlag object at 0x7f8d5ee93550>, 'only_check_args': <absl.flags._flag.BooleanFlag object at 0x7f8d5ee9e990>, 'test_srcdir': <absl.flags._flag.Flag object at 0x7f8d5939b750>, 'bias_deconv': <absl.flags._flag.BooleanFlag object at 0x7f8d4ce2a7d0>, 'weights': <absl.flags._flag.Flag object at 0x7f8d4ce423d0>, 'v': <absl.logging._VerbosityFlag object at 0x7f8d5ee9e290>, 'model': <absl.flags._flag.Flag object at 0x7f8d4ce2ad90>, 'helpxml': <absl.app.HelpXMLFlag object at 0x7f8d4ce424d0>, 'denoise_lbound': <absl.flags._flag.Flag object at 0x7f8d4ce2a910>, 'save_clean_path': <absl.flags._flag.Flag object at 0x7f8d4ce42290>, 'init_l1_weight': <absl.flags._flag.Flag object at 0x7f8d4ce2ab10>}\n",
      "WARNING:tensorflow:From main.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0608 08:52:45.241038 140246037845824 module_wrapper.py:139] From main.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "Using device:  /device:GPU:0\n",
      "WARNING:tensorflow:From main.py:86: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0608 08:52:45.241646 140246037845824 module_wrapper.py:139] From main.py:86: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Creating GAN model\n",
      "*** Applying pre-emphasis of 0.95 ***\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/ops.py:30: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W0608 08:52:45.255233 140246037845824 module_wrapper.py:139] From /home/ec2-user/SageMaker/segan/ops.py:30: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "!!!!!!!!initaial wieght\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/model.py:131: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "W0608 08:52:45.260992 140246037845824 module_wrapper.py:139] From /home/ec2-user/SageMaker/segan/model.py:131: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/ops.py:310: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0608 08:52:45.261431 140246037845824 module_wrapper.py:139] From /home/ec2-user/SageMaker/segan/ops.py:310: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/model.py:161: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W0608 08:52:45.261655 140246037845824 deprecation.py:323] From /home/ec2-user/SageMaker/segan/model.py:161: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W0608 08:52:45.266880 140246037845824 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "W0608 08:52:45.267759 140246037845824 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/python/training/input.py:198: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0608 08:52:45.269448 140246037845824 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/python/training/input.py:198: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0608 08:52:45.270577 140246037845824 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/data_loader.py:24: __init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "W0608 08:52:45.274024 140246037845824 deprecation.py:323] From /home/ec2-user/SageMaker/segan/data_loader.py:24: __init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/data_loader.py:26: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "W0608 08:52:45.275260 140246037845824 module_wrapper.py:139] From /home/ec2-user/SageMaker/segan/data_loader.py:26: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/data_loader.py:29: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "W0608 08:52:45.275466 140246037845824 module_wrapper.py:139] From /home/ec2-user/SageMaker/segan/data_loader.py:29: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/model.py:173: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n",
      "W0608 08:52:45.308871 140246037845824 deprecation.py:323] From /home/ec2-user/SageMaker/segan/model.py:173: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n",
      "*** Building Generator ***\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/generator.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0608 08:52:45.323189 140246037845824 module_wrapper.py:139] From /home/ec2-user/SageMaker/segan/generator.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "Biasing downconv in G\n",
      "Downconv (100, 16384, 1) -> (100, 8192, 16)\n",
      "Adding skip connection downconv 0\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 8192, 16) -> (100, 4096, 32)\n",
      "Adding skip connection downconv 1\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 4096, 32) -> (100, 2048, 32)\n",
      "Adding skip connection downconv 2\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 2048, 32) -> (100, 1024, 64)\n",
      "Adding skip connection downconv 3\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 1024, 64) -> (100, 512, 64)\n",
      "Adding skip connection downconv 4\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 512, 64) -> (100, 256, 128)\n",
      "Adding skip connection downconv 5\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 256, 128) -> (100, 128, 128)\n",
      "Adding skip connection downconv 6\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 128, 128) -> (100, 64, 256)\n",
      "Adding skip connection downconv 7\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 64, 256) -> (100, 32, 256)\n",
      "Adding skip connection downconv 8\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 32, 256) -> (100, 16, 512)\n",
      "Adding skip connection downconv 9\n",
      "-- Enc: prelu activation --\n",
      "Biasing downconv in G\n",
      "Downconv (100, 16, 512) -> (100, 8, 1024)\n",
      "-- Enc: prelu activation --\n",
      "g_dec_depths:  [512, 256, 256, 128, 128, 64, 64, 32, 32, 16, 1]\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 8, 2048) -> (100, 16, 512)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 16, 512)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 16, 1024) -> (100, 32, 256)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 32, 256)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 32, 512) -> (100, 64, 256)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 64, 256)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 64, 512) -> (100, 128, 128)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 128, 128)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 128, 256) -> (100, 256, 128)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 256, 128)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 256, 256) -> (100, 512, 64)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 512, 64)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 512, 128) -> (100, 1024, 64)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 1024, 64)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 1024, 128) -> (100, 2048, 32)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 2048, 32)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 2048, 64) -> (100, 4096, 32)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 4096, 32)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 4096, 64) -> (100, 8192, 16)\n",
      "-- Dec: prelu activation --\n",
      "Fusing skip connection of shape (100, 8192, 16)\n",
      "-- Transposed deconvolution type --\n",
      "Biasing deconv in G\n",
      "Deconv (100, 8192, 32) -> (100, 16384, 1)\n",
      "-- Dec: tanh activation --\n",
      "Amount of alpha vectors:  21\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/ops.py:37: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "W0608 08:52:45.853374 140246037845824 module_wrapper.py:139] From /home/ec2-user/SageMaker/segan/ops.py:37: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "Amount of skip connections:  10\n",
      "Last wave shape:  (100, 16384, 1)\n",
      "*************************\n",
      "num of G returned:  23\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/ops.py:10: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0608 08:52:45.878746 140246037845824 module_wrapper.py:139] From /home/ec2-user/SageMaker/segan/ops.py:10: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "*** Discriminator summary ***\n",
      "D block 0 input shape: (100, 16384, 2) *** biasing D conv *** downconved shape: (100, 8192, 16)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 1 input shape: (100, 8192, 16) *** biasing D conv *** downconved shape: (100, 4096, 32)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 2 input shape: (100, 4096, 32) *** biasing D conv *** downconved shape: (100, 2048, 32)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 3 input shape: (100, 2048, 32) *** biasing D conv *** downconved shape: (100, 1024, 64)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 4 input shape: (100, 1024, 64) *** biasing D conv *** downconved shape: (100, 512, 64)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 5 input shape: (100, 512, 64) *** biasing D conv *** downconved shape: (100, 256, 128)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 6 input shape: (100, 256, 128) *** biasing D conv *** downconved shape: (100, 128, 128)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 7 input shape: (100, 128, 128) *** biasing D conv *** downconved shape: (100, 64, 256)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 8 input shape: (100, 64, 256) *** biasing D conv *** downconved shape: (100, 32, 256)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 9 input shape: (100, 32, 256) *** biasing D conv *** downconved shape: (100, 16, 512)  *** Applying VBN *** Applying Lrelu *** \n",
      "D block 10 input shape: (100, 16, 512) *** biasing D conv *** downconved shape: (100, 8, 1024)  *** Applying VBN *** Applying Lrelu *** \n",
      "discriminator deconved shape:  (100, 8, 1024)\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0608 08:52:46.304363 140246037845824 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/python/layers/core.py:332: apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0608 08:52:46.306230 140246037845824 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/python/layers/core.py:332: apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "discriminator output shape:  (100, 1)\n",
      "*****************************\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/generator.py:130: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "W0608 08:52:46.339417 140246037845824 module_wrapper.py:139] From /home/ec2-user/SageMaker/segan/generator.py:130: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/ops.py:51: The name tf.summary.audio is deprecated. Please use tf.compat.v1.summary.audio instead.\n",
      "\n",
      "W0608 08:52:47.143524 140246037845824 module_wrapper.py:139] From /home/ec2-user/SageMaker/segan/ops.py:51: The name tf.summary.audio is deprecated. Please use tf.compat.v1.summary.audio instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/model.py:259: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n",
      "\n",
      "W0608 08:52:47.151845 140246037845824 module_wrapper.py:139] From /home/ec2-user/SageMaker/segan/model.py:259: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/model.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W0608 08:52:47.168514 140246037845824 module_wrapper.py:139] From /home/ec2-user/SageMaker/segan/model.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "Not clipping D weights\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0608 08:52:47.267637 140246037845824 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "!!!!!!!<tensorflow.python.ops.variable_scope.VariableScope object at 0x7f8d4ce42910>\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/model.py:153: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0608 08:52:53.248233 140246037845824 module_wrapper.py:139] From /home/ec2-user/SageMaker/segan/model.py:153: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0608 08:52:53.249239 140246037845824 deprecation.py:506] From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Loading model weights...\n",
      "[*] Reading checkpoints...\n",
      "segan_v1.1\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/segan/model.py:49: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0608 08:52:54.399157 140246037845824 module_wrapper.py:139] From /home/ec2-user/SageMaker/segan/model.py:49: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from segan_v1.1/SEGAN-41700\n",
      "I0608 08:52:54.710649 140246037845824 saver.py:1290] Restoring parameters from segan_v1.1/SEGAN-41700\n",
      "[*] Read SEGAN-41700\n",
      "preemph test wave with 0.95\n",
      "WARNING:tensorflow:From main.py:62: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0608 08:53:24.329040 140246037845824 module_wrapper.py:139] From main.py:62: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "test wave shape:  (4770654,)\n",
      "test wave min:-0.296431571245  max:0.27285349369\n",
      "start timer\n",
      "Cleaning chunk 0 -> 16384\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 16384 -> 32768\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 32768 -> 49152\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 49152 -> 65536\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 65536 -> 81920\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 81920 -> 98304\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 98304 -> 114688\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 114688 -> 131072\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 131072 -> 147456\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 147456 -> 163840\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 163840 -> 180224\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 180224 -> 196608\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 196608 -> 212992\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 212992 -> 229376\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 229376 -> 245760\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 245760 -> 262144\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 262144 -> 278528\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 278528 -> 294912\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 294912 -> 311296\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 311296 -> 327680\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 327680 -> 344064\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 344064 -> 360448\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 360448 -> 376832\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 376832 -> 393216\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 393216 -> 409600\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 409600 -> 425984\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 425984 -> 442368\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 442368 -> 458752\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 458752 -> 475136\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 475136 -> 491520\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 491520 -> 507904\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 507904 -> 524288\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 524288 -> 540672\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 540672 -> 557056\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 557056 -> 573440\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 573440 -> 589824\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 589824 -> 606208\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 606208 -> 622592\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 622592 -> 638976\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 638976 -> 655360\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 655360 -> 671744\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 671744 -> 688128\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 688128 -> 704512\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 704512 -> 720896\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 720896 -> 737280\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 737280 -> 753664\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 753664 -> 770048\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 770048 -> 786432\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 786432 -> 802816\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 802816 -> 819200\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 819200 -> 835584\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 835584 -> 851968\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 851968 -> 868352\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 868352 -> 884736\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 884736 -> 901120\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 901120 -> 917504\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 917504 -> 933888\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 933888 -> 950272\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 950272 -> 966656\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 966656 -> 983040\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 983040 -> 999424\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 999424 -> 1015808\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1015808 -> 1032192\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1032192 -> 1048576\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1048576 -> 1064960\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1064960 -> 1081344\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1081344 -> 1097728\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1097728 -> 1114112\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1114112 -> 1130496\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1130496 -> 1146880\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1146880 -> 1163264\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1163264 -> 1179648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1179648 -> 1196032\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1196032 -> 1212416\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1212416 -> 1228800\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1228800 -> 1245184\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1245184 -> 1261568\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1261568 -> 1277952\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1277952 -> 1294336\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1294336 -> 1310720\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1310720 -> 1327104\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1327104 -> 1343488\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1343488 -> 1359872\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1359872 -> 1376256\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1376256 -> 1392640\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1392640 -> 1409024\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1409024 -> 1425408\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1425408 -> 1441792\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1441792 -> 1458176\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1458176 -> 1474560\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1474560 -> 1490944\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1490944 -> 1507328\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1507328 -> 1523712\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1523712 -> 1540096\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1540096 -> 1556480\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1556480 -> 1572864\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1572864 -> 1589248\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1589248 -> 1605632\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1605632 -> 1622016\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1622016 -> 1638400\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1638400 -> 1654784\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1654784 -> 1671168\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1671168 -> 1687552\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1687552 -> 1703936\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1703936 -> 1720320\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1720320 -> 1736704\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1736704 -> 1753088\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1753088 -> 1769472\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1769472 -> 1785856\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1785856 -> 1802240\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1802240 -> 1818624\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1818624 -> 1835008\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1835008 -> 1851392\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1851392 -> 1867776\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1867776 -> 1884160\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1884160 -> 1900544\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1900544 -> 1916928\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1916928 -> 1933312\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1933312 -> 1949696\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1949696 -> 1966080\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1966080 -> 1982464\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1982464 -> 1998848\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 1998848 -> 2015232\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2015232 -> 2031616\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2031616 -> 2048000\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2048000 -> 2064384\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2064384 -> 2080768\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2080768 -> 2097152\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2097152 -> 2113536\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2113536 -> 2129920\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2129920 -> 2146304\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2146304 -> 2162688\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2162688 -> 2179072\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2179072 -> 2195456\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2195456 -> 2211840\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2211840 -> 2228224\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2228224 -> 2244608\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2244608 -> 2260992\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2260992 -> 2277376\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2277376 -> 2293760\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2293760 -> 2310144\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2310144 -> 2326528\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2326528 -> 2342912\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2342912 -> 2359296\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2359296 -> 2375680\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2375680 -> 2392064\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2392064 -> 2408448\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2408448 -> 2424832\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2424832 -> 2441216\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2441216 -> 2457600\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2457600 -> 2473984\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2473984 -> 2490368\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2490368 -> 2506752\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2506752 -> 2523136\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2523136 -> 2539520\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2539520 -> 2555904\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2555904 -> 2572288\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2572288 -> 2588672\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2588672 -> 2605056\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2605056 -> 2621440\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2621440 -> 2637824\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2637824 -> 2654208\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2654208 -> 2670592\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2670592 -> 2686976\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2686976 -> 2703360\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2703360 -> 2719744\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2719744 -> 2736128\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2736128 -> 2752512\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2752512 -> 2768896\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2768896 -> 2785280\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2785280 -> 2801664\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2801664 -> 2818048\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2818048 -> 2834432\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2834432 -> 2850816\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2850816 -> 2867200\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2867200 -> 2883584\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2883584 -> 2899968\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2899968 -> 2916352\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2916352 -> 2932736\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2932736 -> 2949120\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2949120 -> 2965504\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2965504 -> 2981888\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2981888 -> 2998272\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 2998272 -> 3014656\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3014656 -> 3031040\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3031040 -> 3047424\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3047424 -> 3063808\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3063808 -> 3080192\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3080192 -> 3096576\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3096576 -> 3112960\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3112960 -> 3129344\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3129344 -> 3145728\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3145728 -> 3162112\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3162112 -> 3178496\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3178496 -> 3194880\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3194880 -> 3211264\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3211264 -> 3227648\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3227648 -> 3244032\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3244032 -> 3260416\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3260416 -> 3276800\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3276800 -> 3293184\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3293184 -> 3309568\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3309568 -> 3325952\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3325952 -> 3342336\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3342336 -> 3358720\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3358720 -> 3375104\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3375104 -> 3391488\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3391488 -> 3407872\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3407872 -> 3424256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3424256 -> 3440640\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3440640 -> 3457024\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3457024 -> 3473408\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3473408 -> 3489792\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3489792 -> 3506176\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3506176 -> 3522560\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3522560 -> 3538944\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3538944 -> 3555328\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3555328 -> 3571712\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3571712 -> 3588096\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3588096 -> 3604480\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3604480 -> 3620864\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3620864 -> 3637248\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3637248 -> 3653632\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3653632 -> 3670016\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3670016 -> 3686400\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3686400 -> 3702784\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3702784 -> 3719168\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3719168 -> 3735552\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3735552 -> 3751936\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3751936 -> 3768320\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3768320 -> 3784704\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3784704 -> 3801088\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3801088 -> 3817472\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3817472 -> 3833856\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3833856 -> 3850240\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3850240 -> 3866624\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3866624 -> 3883008\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3883008 -> 3899392\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3899392 -> 3915776\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3915776 -> 3932160\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3932160 -> 3948544\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3948544 -> 3964928\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3964928 -> 3981312\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3981312 -> 3997696\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 3997696 -> 4014080\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4014080 -> 4030464\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4030464 -> 4046848\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4046848 -> 4063232\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4063232 -> 4079616\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4079616 -> 4096000\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4096000 -> 4112384\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4112384 -> 4128768\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4128768 -> 4145152\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4145152 -> 4161536\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4161536 -> 4177920\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4177920 -> 4194304\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4194304 -> 4210688\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4210688 -> 4227072\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4227072 -> 4243456\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4243456 -> 4259840\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4259840 -> 4276224\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4276224 -> 4292608\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4292608 -> 4308992\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4308992 -> 4325376\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4325376 -> 4341760\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4341760 -> 4358144\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4358144 -> 4374528\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4374528 -> 4390912\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4390912 -> 4407296\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4407296 -> 4423680\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4423680 -> 4440064\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4440064 -> 4456448\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4456448 -> 4472832\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4472832 -> 4489216\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4489216 -> 4505600\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4505600 -> 4521984\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4521984 -> 4538368\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4538368 -> 4554752\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4554752 -> 4571136\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4571136 -> 4587520\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4587520 -> 4603904\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4603904 -> 4620288\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4620288 -> 4636672\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4636672 -> 4653056\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4653056 -> 4669440\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4669440 -> 4685824\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4685824 -> 4702208\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4702208 -> 4718592\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4718592 -> 4734976\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4734976 -> 4751360\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4751360 -> 4767744\n",
      "canvas w shape:  (16384,)\n",
      "Cleaning chunk 4767744 -> 4770654\n",
      "canvas w shape:  (16384,)\n",
      "Removing padding of 13474 samples\n",
      "finish 52.1166660786\n",
      "c wave min:-0.740963697433  max:0.832789719105\n",
      "Done cleaning record_noise/record_noise_28_clip_0.wav and saved to clean/record_noise_28_clip_0.wav\n"
     ]
    }
   ],
   "source": [
    "!sh clean_wav.sh ../../../record_noise/record_noise_28_clip_0.wav ../../../clean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}